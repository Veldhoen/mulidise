%Reproducing existing work with more languages
%New approach: based on par2vec (2 flavors)


\subsection{Evaluation}
We evaluate our mutlilingual word embeddings on the same real-world task as \cite{klementiev2012inducing} and \cite{hermann2013multilingual}: crosslingual document classification. The task is based on Reuters corpora, which has topic-annotated documents in English, French, German, Italian and Spanish. These languages are also in the Europarl data. Only documents that are assigned a single topic are used.

Each document is represented by the average of the representations of its tokens (in \cite{klementiev2012inducing}), or sentences (in \cite{hermann2013multilingual}).
An averaged version of the perceptron algorithm is trained for document classification in one language, and tested on data in another.

We thus compute classification accuracy to compare the existing approaches described above to each other and to the new models introduced in \ref{s:newApproach}.

%As a baseline, \cite{klementiev2012inducing} compares to wordcount features. Translations are done via glossing or machine translation.





%Alternative:
The WIT TED corpus \cite{cettolo2012} contains short documents with transcriptions and translations of TED talks, with topic annotations. The original distribution was aimed at machine translation, but \cite{hermann2014multilingual} propose it for a multilingual document classification task.


English paired in both directions with other languages, seven of which are also in the Europarl corpus: Spanish, German, Italian, Dutch, Portuguese, Polish, and Romanian.
%Slovenian is not in the Hermann-Blunsom dataset!
% Non-Europarl: Arabic, Russian, Turkish, and Chinese, Farsi, 

The classification labels in this set are technology, culture, science, global issues, design, business, entertainment, arts, politics, education, art, health, creativity, economics, and biology. Note that a document can have more than one topic annotation. 






%In \cite{mikolov2013exploiting}, the evaluation is performed on a test set of gold-standard word translations, again from Google Translate. The word representation in the source language is transformed using $W$, and a ranked list of the nearest words in the target language is the output. The precision at ranks 1 and 5 is reported. 
% Gaan we dat nou ook nog doen of niet?

%For visualizing the vector space, we will project a selection of words onto a plane and highlight semantic relationships.
%We will also visualize rare words and words with high variability across languages.
